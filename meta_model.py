# -*- coding: utf-8 -*-
"""Meta model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ojz71RfZq6OzOL2YhF8NatNqyQfRQaKu
"""

# Xử lý dữ liệu
import pandas as pd
import numpy as np
import os
import re
# import missingno as msno
# import statsmodels.api as sm
# from statsmodels.tsa.interp import denton
import warnings
# Lưu model
import joblib
import json

# Machine Learning
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LinearRegression
import lightgbm as lgb
import xgboost as xgb
from scipy.stats import randint
from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, MaxAbsScaler, QuantileTransformer, PowerTransformer
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix
# Deep Learning - LSTM
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard
from tensorflow.keras.optimizers import Adam, RMSprop
from keras.models import load_model
import pandas as pd
# Visualization
import matplotlib.pyplot as plt
import seaborn as sns
# import plotly.express as px

# Warning
import warnings
warnings.filterwarnings('ignore')

from IPython.display import display
# Đặt định dạng hiển thị số với 2 chữ số thập phân
pd.options.display.float_format = '{:,.2f}'.format
# Bỏ giới hạn hiển thị dòng và cột
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

"""File này sẽ sử dụng kết quả dự đoán của mô hình dự đoán giá cổ phiếu từ Báo cáo tài chính và Thị trường, đồng thời sẽ tích hợp các Features thu được từ việc phân tích tin tức với LLM."""

# Đọc dữ liệu
def basic_stats(df, name):
    print(name)
    display(df.head())
    display(df.tail())
    print(df.info())
    print("Số giá trị bị rỗng:")
    print(df.isnull().sum())
    print("Thống kê các giá trị:")
    display(df.describe())
    print(df.nunique())
    print("Các giá trị độc nhất của từng trường dữ liệu:")
    for col in list(df.columns):
        print(f"{col}:")
        print(f"{list(df[col].unique())[:20]}..., số giá trị độc nhất: {len(list(df[col].unique()))}")
    print("Các bản ghi bị trùng:")
    display(df[df.duplicated()])

def convert_to_number(s):
    unit_multipliers = {
        'K': 1e3,
        'M': 1e6,
        'B': 1e9
    }
    if isinstance(s, str):
        match = re.match(r"([0-9.]+)([a-zA-Z]+)?", s.strip())
        if match:
            number = float(match.group(1))
            unit = match.group(2)
            if unit:
                return number * unit_multipliers.get(unit.upper(), 1)
            else:
                return number
    elif isinstance(s, (int, float)):
        return s
# Hàm làm sạch dữ liệu lịch sử giá 2 cổ phiếu
def clean_history_price(df):
    rename_map = {
        'Ngày': 'Date',
        'Lần cuối': 'Close',
        'Mở': 'Open',
        'Cao': 'High',
        'Thấp': 'Low',
        'KL': 'Volume',
        '% Thay đổi': 'Change %'
    }
    df = df.rename(columns=rename_map)
    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)

    df['Volume'] = df['Volume'].apply(convert_to_number)
    df['Change %'] = df['Change %'].str.rstrip('%').astype(float) / 100

    # Convert 'Close', 'Open', 'High', 'Low' to numeric
    for col in ['Close', 'Open', 'High', 'Low']:
        df[col] = df[col].str.replace(',', '').astype(float)

    df = df.sort_values(by='Date')
    df = df.set_index('Date')
    return df

def clean_prediction(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values(by='Date')
    df = df.set_index('Date')
    return df

def clean_news(df):
    df = df.rename(columns = {'Unnamed: 0':'Date'})
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values(by='Date')
    df = df.set_index('Date')
    df = df.drop(columns = ['news_avg_title_len','news_avg_summary_len']) # Do việc sử dụng độ dài tiêu đề tin tức và độ dài tóm tắt tin tức làm feature là không thiết thực
    return df


def ultimate_clean(data_dict):
    df_dict = data_dict.copy()
    for key, value in df_dict.items():
        df = value.copy()
        if 'news' in key:
            df = clean_news(df)
        elif 'prediction' in key:
            df = clean_prediction(df)
        elif 'Lịch sử' in key:
            df = clean_history_price(df)
        else:
            pass
        df_dict[key] = df
    return df_dict



def open_model(path):
    if path.endswith('.pkl'):
        return joblib.load(path)
    return load_model(path)
def open_json(path):
    with open(path, "r") as f:
        metrics = json.load(f)
    return metrics

"""Có thể thấy, mô hình dự đoán từ dữ liệu thị trường sẽ cho kết quả chính xác hơn so với dữ liệu từ báo cáo tài chính. Vậy nên khi dùng giá trị dự đoán từ trước, sẽ ưu tiên sử dụng dữ liệu từ thị trường."""

def merging_df(data_dict, ticker):
    df_dict = data_dict.copy()
    for key, value in df_dict.items():
        df = value.copy()
        if key == f'Dữ liệu Lịch sử {ticker}.csv':
            df = df.drop(columns=['Open', 'High', 'Low'])
            price_history = df
        elif key == f'{ticker}_news_features.csv':
            news = df
        elif key == f'prediction_{ticker}_market.csv':
            market = df
            market = market.rename(columns = {f'prediction_{ticker}_market':'predict_value'})
        elif key == f'prediction_{ticker}_bctc.csv':
            bctc = df
            bctc = bctc.rename(columns = {f'prediction_{ticker}_bctc':'predict_value'})
        else:
            pass
    result = pd.merge(price_history, news, left_index=True, right_index=True, how='left')
    result = pd.merge(result, market, left_index=True, right_index=True, how='left')
    result['predict_value'] = result['predict_value'].combine_first(bctc['predict_value'])
    return result


# Tạo các giá trị MA và lags
def ma_and_lags(df):
    numeric_cols = df.columns.to_list()
    for col in numeric_cols:
        df[f'{col}_ma_3_days'] = df[col].rolling(window=3).mean()
        df[f'{col}_ma_7_days'] = df[col].rolling(window=7).mean()
        for i in range(1,8):
            df[f'{col}_lags_{i}_days'] = df[col].shift(i)
    df = df.dropna()
    basic_stats(df,'test')
    return df


"""## Xây dựng mô hình"""

# Hàm đánh giá mô hình
def mae_percent(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    error = np.abs(y_pred - y_true) / np.where(y_true == 0, 1, y_true)
    return np.mean(error) * 100

def mse_percent(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    error = ((y_pred - y_true) / np.where(y_true == 0, 1, y_true)) ** 2
    return np.mean(error) * 100

def rmse_percent(y_true, y_pred):
    return np.sqrt(mse_percent(y_true, y_pred))
def evaluate_model(y_true, y_pred, task_type='regression'):
    """
    Đánh giá mô hình cho classification hoặc regression.

    Với classification: tính Accuracy, Precision, Recall, F1-Score và hiển thị Confusion Matrix.
    Với regression: tính MSE, MAE, RMSE và R2 Score.
    """
    # Loại bỏ các giá trị NaN, inf
    valid_mask = np.isfinite(y_true) & np.isfinite(y_pred)
    y_true = y_true[valid_mask]
    y_pred = y_pred[valid_mask]
    if task_type == 'classification':
        y_pred_label = (y_pred > 0.5).astype(int)
        acc = accuracy_score(y_true, y_pred_label)
        prec = precision_score(y_true, y_pred_label)
        rec = recall_score(y_true, y_pred_label)
        f1 = f1_score(y_true, y_pred_label)
        roc_auc = roc_auc_score(y_true, y_pred)
        cm = confusion_matrix(y_true, y_pred_label)
        report = classification_report(y_true, y_pred_label)
        print("Classification Metrics:")
        print(f"  Accuracy: {acc:.4f}")
        print(f"  Precision: {prec:.4f}")
        print(f"  Recall: {rec:.4f}")
        print(f"  F1-Score: {f1:.4f}")
        print(f"  ROC_AUC: {roc_auc:.4f}")
        print("Confusion Matrix:")
        print(cm)
        print("Classification Report:")
        print(report)
        return {
            'Accuracy':acc,
            'Precision':prec,
            'Recall':rec,
            'f1_score':f1,
            'roc_auc':roc_auc
        }
    elif task_type == 'regression':
        mse = mse_percent(y_true, y_pred)
        mae = mae_percent(y_true, y_pred)
        rmse = rmse_percent(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)*100
        print("Regression Metrics:")
        print(f"  MSE: {mse:.4f}%")
        print(f"  MAE: {mae:.4f}%")
        print(f"  RMSE: {rmse:.4f}%")
        print(f"  R2 Score: {r2:.4f}%")
        return {
            'mse':mse,
            'mae':mae,
            'rmse':rmse,
            'r2_score':r2
        }
    else:
        raise ValueError("task_type phải là 'regression' hoặc 'classification'")
        return None

# Hàm xây dựng mô hình LSTM
def build_lstm_model(
    input_shape,
    task_type='regression',
    lstm_units=[64, 32],
    dropout_rates=[0.2, 0.2],
    bidirectional=False,
    use_batch_norm=False,
    dense_units=[16],
    dense_dropout_rates=[0.1],
    optimizer='adam',
    learning_rate=1e-5,
    **kwargs
):
    """
    Xây dựng mô hình LSTM phức tạp với các tiện ích sau:
      - Nhiều lớp LSTM (tùy chọn Bidirectional)
      - BatchNormalization
      - Phần đầu Fully-connected (Dense layers)

    Tham số:
      input_shape: tuple, (timesteps, features)
      task_type: 'regression' hoặc 'classification'
      lstm_units: list int, số lượng units từng lớp LSTM
      dropout_rates: list float, tỉ lệ dropout sau mỗi lớp LSTM
      bidirectional: bool, sử dụng LSTM hai chiều hay không
      use_batch_norm: bool, thêm BatchNormalization sau mỗi LSTM
      dense_units: list int, số lượng units cho các lớp Dense
      dense_dropout_rates: list float, dropout cho các lớp Dense
      optimizer: 'adam' hoặc 'rmsprop' hoặc instance optimizer
      learning_rate: float, learning rate khởi tạo
      **kwargs: các tham số bổ sung (nếu có)

    Trả về:
      model: Keras Model đã compile sẵn
    """
    # Lớp đầu vào
    inputs = Input(shape=input_shape)
    x = inputs

    # Xếp chồng các lớp LSTM
    for idx, units in enumerate(lstm_units):
        return_sequences = idx < len(lstm_units) - 1
        lstm_layer = LSTM(units, return_sequences=return_sequences)
        if bidirectional:
            x = Bidirectional(lstm_layer)(x)
        else:
            x = lstm_layer(x)

        x = Dropout(dropout_rates[idx])(x)
        if use_batch_norm:
            x = BatchNormalization()(x)

    # Phần đầu Fully-connected
    for idx, units in enumerate(dense_units):
        x = Dense(units, activation='relu')(x)
        if dense_dropout_rates and idx < len(dense_dropout_rates):
            x = Dropout(dense_dropout_rates[idx])(x)

    # Lớp đầu ra
    if task_type == 'classification':
        activation = 'sigmoid'
        loss = 'binary_crossentropy'
        metrics = ['accuracy']
        outputs = Dense(1, activation=activation)(x)
    elif task_type == 'regression':
        activation = 'linear'
        loss = 'mse'
        metrics = ['mae']
        outputs = Dense(1, activation=activation)(x)
    else:
        raise ValueError("task_type phải là 'regression' hoặc 'classification'")

    model = Model(inputs, outputs)

    # Chọn optimizer
    if isinstance(optimizer, str):
        if optimizer.lower() == 'adam':
            opt = Adam(learning_rate=learning_rate)
        elif optimizer.lower() == 'rmsprop':
            opt = RMSprop(learning_rate=learning_rate)
        else:
            raise ValueError(f"Chưa hỗ trợ optimizer: {optimizer}")
    else:
        opt = optimizer

    model.compile(optimizer=opt, loss=loss, metrics=metrics)
    return model

def fine_tune_lstm_model(
    model,
    X_train, y_train,
    X_val=None, y_val=None,
    epochs=1000,
    batch_size=32,
    model_dir='models',
    checkpoint_name='best_model.keras',
    early_stop_patience=15,
    reduce_lr_patience=3,
    tensorboard_logdir='logs',
    verbose=1
):
    """
    Fine-tune mô hình với các callbacks:
      - Dừng sớm (EarlyStopping)
      - Lưu mô hình tốt nhất (ModelCheckpoint)
      - Giảm learning rate khi không cải thiện (ReduceLROnPlateau)
      - Ghi log cho TensorBoard (TensorBoard)

    Trả về:
      history: Keras History object chứa lịch sử huấn luyện
    """
    # Tạo thư mục lưu mô hình và logs
    os.makedirs(model_dir, exist_ok=True)
    os.makedirs(tensorboard_logdir, exist_ok=True)

    callbacks = []
    # Dừng sớm
    callbacks.append(
        EarlyStopping(
            monitor='val_loss' if X_val is not None else 'loss',
            patience=early_stop_patience,
            restore_best_weights=True)
    )
    # Lưu mô hình tốt nhất
    checkpoint_path = os.path.join(model_dir, checkpoint_name)
    callbacks.append(
        ModelCheckpoint(
            filepath=checkpoint_path,
            monitor='val_loss' if X_val is not None else 'loss',
            save_best_only=True)
    )
    # Giảm learning rate khi plateau
    callbacks.append(
        ReduceLROnPlateau(
            monitor='val_loss' if X_val is not None else 'loss',
            factor=0.5,
            patience=reduce_lr_patience)
    )
    # Ghi log cho TensorBoard
    callbacks.append(
        TensorBoard(log_dir=tensorboard_logdir)
    )

    # Huấn luyện mô hình
    if X_val is not None and y_val is not None:
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=verbose
        )
    else:
        history = model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=verbose
        )

    return history

def try_scalers(X, scalers):
    best = {'scaler': None, 'score': float('inf'), 'X_scaled': None}
    for scaler in scalers:
        try:
            Xs = scaler.fit_transform(X)
            score = ((Xs - Xs.mean())**2).mean()
            if score < best['score']:
                best.update({'scaler': scaler, 'score': score, 'X_scaled': Xs})
        except Exception:
            continue
    return best['scaler'], best['X_scaled']

def run_model_pipeline(features, task, model_type, build_lstm_model, fine_tune_lstm_model, evaluate_model,
                        test_size=0.2, random_state=42, return_importance=False):
    X = features.drop(columns='Target')
    y = features['Target']
    split_idx = int((1 - test_size) * len(features))
    X_train, X_val = X.iloc[:split_idx].values, X.iloc[split_idx:].values
    y_train, y_val = y.iloc[:split_idx].values, y.iloc[split_idx:].values

    scalers = [
        RobustScaler(), MinMaxScaler(), StandardScaler(), MaxAbsScaler(),
        QuantileTransformer(output_distribution='normal')
    ]
    x_scaler, X_train_scaled = try_scalers(X_train, scalers)
    X_val_scaled = x_scaler.transform(X_val)

    y_scaler = None
    if task == 'regression':
        y_scalers = [MinMaxScaler(), StandardScaler(), RobustScaler()]
        y_scaler, y_train_scaled = try_scalers(y_train.reshape(-1,1), y_scalers)
        y_train_scaled = y_train_scaled.ravel()
        y_val_scaled = y_scaler.transform(y_val.reshape(-1,1)).ravel()
    else:
        y_train_scaled, y_val_scaled = y_train, y_val
        y_scalers = None

    if model_type == 'lstm':
        X_train_in = X_train_scaled.reshape((len(X_train_scaled), 1, X_train_scaled.shape[1]))
        X_val_in = X_val_scaled.reshape((len(X_val_scaled), 1, X_val_scaled.shape[1]))
        model = build_lstm_model(input_shape=(1, X_train_scaled.shape[1]), task_type=task)
        fine_tune_lstm_model(model, X_train_in, y_train_scaled, X_val_in, y_val_scaled)
        y_pred_raw = model.predict(X_val_in).ravel()
        importance_df = None
    else:
        if task == 'classification':
            if model_type == 'rf':
                base = RandomForestClassifier(random_state=random_state)
                params = {'n_estimators': randint(50,200), 'max_depth': randint(3,10)}
            elif model_type == 'lgb':
                base = lgb.LGBMClassifier(random_state=random_state)
                params = {'n_estimators': randint(50,200), 'num_leaves': randint(20,100)}
            else:
                base = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_state)
                params = {'n_estimators': randint(50,200), 'max_depth': randint(3,10)}
        else:
            if model_type == 'rf':
                base = RandomForestRegressor(random_state=random_state)
                params = {'n_estimators': randint(50,200), 'max_depth': randint(3,10)}
            elif model_type == 'lgb':
                base = lgb.LGBMRegressor(random_state=random_state)
                params = {'n_estimators': randint(50,200), 'num_leaves': randint(20,100)}
            elif model_type == 'lr':
                base = LinearRegression()
                params = {}  # Không cần tìm hyperparameter
            else:
                base = xgb.XGBRegressor(random_state=random_state)
                params = {'n_estimators': randint(50, 200), 'max_depth': randint(3, 10)}
        if params:
            search = RandomizedSearchCV(base, param_distributions=params, n_iter=20, cv=3, random_state=random_state)
            search.fit(X_train_scaled, y_train_scaled)
            model = search.best_estimator_
        else:
            base.fit(X_train_scaled, y_train_scaled)
            model = base
        y_pred_raw = model.predict(X_val_scaled)

    importance_df = None
    if return_importance:
        if hasattr(model, 'feature_importances_'):
            importance_df = pd.DataFrame({
                'feature': X.columns,
                'importance': model.feature_importances_
            })
        elif hasattr(model, 'coef_'):
            importance_df = pd.DataFrame({
                'feature': X.columns,
                'importance': np.abs(model.coef_)
            })
        if importance_df is not None:
            importance_df = importance_df.sort_values(by='importance', ascending=False)

    if task == 'regression' and y_scaler:
        y_pred = y_scaler.inverse_transform(y_pred_raw.reshape(-1,1)).ravel()
        y_true = y_val
    else:
        y_pred = y_pred_raw
        y_true = y_val

    metrics = evaluate_model(y_true, y_pred, task_type=task)
    return model, x_scaler, y_scaler, y_pred, metrics, importance_df

def permutation_importance_lstm(features, task, build_lstm_model, fine_tune_lstm_model,
                                x_scaler, y_scaler=None, test_size=0.2, random_state=42, n_repeats=5):
    from copy import deepcopy

    # Tách dữ liệu
    X = features.drop(columns='Target')
    y = features['Target']
    feature_names = X.columns.tolist()

    split_idx = int((1 - test_size) * len(features))
    X_train, X_val = X.iloc[:split_idx].values, X.iloc[split_idx:].values
    y_train, y_val = y.iloc[:split_idx].values, y.iloc[split_idx:].values

    # Scale dữ liệu
    X_train_scaled = x_scaler.transform(X_train)
    X_val_scaled = x_scaler.transform(X_val)

    if task == 'regression':
        if y_scaler is None:
            raise ValueError("Với bài toán regression, cần cung cấp y_scaler.")
        y_train_scaled = y_scaler.transform(y_train.reshape(-1, 1)).ravel()
        y_val_scaled = y_scaler.transform(y_val.reshape(-1, 1)).ravel()
    else:
        y_train_scaled = y_train
        y_val_scaled = y_val

    # Reshape cho LSTM
    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
    X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))

    # Huấn luyện mô hình
    model = build_lstm_model(input_shape=(1, X_train_scaled.shape[1]), task_type=task)
    fine_tune_lstm_model(model, X_train_lstm, y_train_scaled, X_val_lstm, y_val_scaled)

    # Dự đoán gốc
    base_preds = model.predict(X_val_lstm).ravel()
    if task == 'regression':
        base_score = mean_squared_error(y_val_scaled, base_preds)
    else:
        base_preds_label = (base_preds > 0.5).astype(int)
        base_score = f1_score(y_val_scaled, base_preds_label)

    # Tính permutation importance
    importances = []
    for i in range(X_val_lstm.shape[2]):
        deltas = []
        for _ in range(n_repeats):
            X_val_perm = deepcopy(X_val_lstm)
            np.random.shuffle(X_val_perm[:, 0, i])
            preds = model.predict(X_val_perm).ravel()
            if task == 'regression':
                score = mean_squared_error(y_val_scaled, preds)
                delta = score - base_score
            else:
                preds_label = (preds > 0.5).astype(int)
                score = f1_score(y_val_scaled, preds_label)
                delta = base_score - score
            deltas.append(delta)
        importances.append(np.mean(deltas))

    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    }).sort_values(by='importance', ascending=False)

    return importance_df.reset_index(drop=True)

def run_all_models(features, task, build_lstm_model, fine_tune_lstm_model, evaluate_model,
                   ticker=None, test_size=0.2, random_state=42):
    model_types = ['lstm', 'rf', 'lgb', 'xgb']
    best_result = None
    best_score = None
    best_type = None
    best_importance = None

    for mt in model_types:
        res = run_model_pipeline(features, task, mt, build_lstm_model, fine_tune_lstm_model, evaluate_model,
                                 test_size=test_size, random_state=random_state, return_importance=True)
        metrics = res[4]
        score = metrics['f1_score'] if task == 'classification' else -metrics['rmse']

        if mt == 'lstm':
            importance = permutation_importance_lstm(features, task, build_lstm_model, fine_tune_lstm_model, res[1], res[2])
        else:
            importance = res[5]

        if best_score is None or score > best_score:
            best_score = score
            best_result = res
            best_type = mt
            best_importance = importance
    return best_result[0], best_result[1], best_result[2], best_result[3], best_result[4], best_importance

def create_target(df, task):
    result = df.copy()
    if 'Target' in result.columns:
        result = result.drop(columns='Target')
    if task == 'classification':
        result['Target'] = (result['Close'].shift(1) < result['Close']).astype(int)
        result = result.drop(columns='Close')
        result = result.dropna()
        return result
    elif task == 'regression':
        result = result.rename(columns={'Close': 'Target'})
        return result

    else:
        pass


def plot_actual_vs_predicted(actual, predicted, ticker):
    plt.figure(figsize=(12, 6))
    plt.plot(actual, label='Actual', marker='o')
    plt.plot(predicted, label='Predicted', marker='x')
    plt.title(f'Actual vs Predicted Stock Prices for {ticker}')
    plt.xlabel('Time')
    plt.ylabel('Value')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

def compare(df, predict, ticker, ratio):
    split_idx = int(ratio * df.shape[0])
    actual_df = df.iloc[split_idx:][['Target']]
    predicted_df = pd.DataFrame(predict, columns=['Predicted'], index=actual_df.index)
    result = pd.concat([actual_df, predicted_df], axis=1)
    plot_actual_vs_predicted(result['Target'], result['Predicted'], ticker)
    return None

def predict_and_save(model, X_input_raw, x_scaler, y_scaler, ticker):
    # 1. Scale X
    X_scaled = x_scaler.transform(X_input_raw)
    # 2. Dự đoán
    if isinstance(model, Sequential):
        X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))
        pred_scaled = model.predict(X_scaled)
    else:
        pred_scaled = model.predict(X_scaled).reshape(-1, 1)
    # 3. Scale ngược dự đoán trở lại giá trị đúng
    pred = y_scaler.inverse_transform(pred_scaled).flatten()
    # 4. Tạo DataFrame
    result_df = pd.DataFrame({f'Prediction value': pred}, index=X_input_raw.index)
    # os.makedirs(f"{folder}/Total prediction value", exist_ok=True)
    # save_path = f"{folder}/Total prediction value/prediction_{ticker}.csv"
    # result_df.to_csv(save_path)
    return result_df


"""Sử dụng LSTM để dự đoán cho giá trị tương lai 3 ngày tới"""

def lstm_train_finetune_predict(
    pred_df,
    actual_df,
    scaler,
    lookback=360,
    epochs_pretrain=1000,
    epochs_finetune=1000,
    batch_size=32,
    predict_days=7,
):
    def create_sequences(data, lookback):
        X, y = [], []
        for i in range(lookback, len(data)):
            X.append(data[i - lookback:i, 0])
            y.append(data[i, 0])
        X = np.array(X)
        y = np.array(y)
        return X.reshape(X.shape[0], X.shape[1], 1), y

    pred_series = pred_df['Prediction value'].values.reshape(-1, 1)
    scaled_pred = scaler.fit_transform(pred_series)
    X_pred, y_pred = create_sequences(scaled_pred, lookback)
    split = int(len(X_pred) * 0.8)
    X_train_pred, X_val_pred = X_pred[:split], X_pred[split:]
    y_train_pred, y_val_pred = y_pred[:split], y_pred[split:]

    model_base = Sequential()
    model_base.add(LSTM(50, return_sequences=True, input_shape=(lookback, 1)))
    model_base.add(LSTM(30))
    model_base.add(Dropout(0.2))
    model_base.add(Dense(1))
    model_base.compile(optimizer='adam', loss='mean_squared_error')

    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.0001, patience=7)

    model_base.fit(
        X_train_pred, y_train_pred,
        validation_data=(X_val_pred, y_val_pred),
        epochs=epochs_pretrain,
        batch_size=batch_size,
        callbacks=[early_stop, reduce_lr],
        verbose=1
    )

    actual_series = actual_df['Target'].values.reshape(-1, 1)
    scaled_actual = scaler.fit_transform(actual_series)
    X_actual, y_actual = create_sequences(scaled_actual, lookback)
    split_act = int(len(X_actual) * 0.8)
    X_train_act, X_val_act = X_actual[:split_act], X_actual[split_act:]
    y_train_act, y_val_act = y_actual[:split_act], y_actual[split_act:]

    def fine_tune(model, X_train, y_train, X_val, y_val, epochs, batch_size):
        model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=[early_stop, reduce_lr],
            verbose=1
        )
        y_val_pred_scaled = model.predict(X_val).ravel()
        y_val_pred_inv = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
        y_val_true_inv = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
        return evaluate_model(y_val_true_inv, y_val_pred_inv), model

    metrics_base, model_base = fine_tune(
        model_base, X_train_act, y_train_act, X_val_act, y_val_act,
        epochs_finetune, batch_size
    )

    input_layer = Input(shape=(lookback, 1))
    x = LSTM(50, return_sequences=True)(input_layer)
    x = LSTM(30)(x)
    x = Dropout(0.2)(x)
    x = Dense(20, activation='relu')(x)
    output_layer = Dense(1)(x)
    model_new = Model(inputs=input_layer, outputs=output_layer)

    for i, layer in enumerate(model_base.layers):
        if i == 0:
            model_new.layers[1].set_weights(layer.get_weights())
        elif i == 1:
            model_new.layers[2].set_weights(layer.get_weights())

    model_new.compile(optimizer='adam', loss='mean_squared_error')

    metrics_new, model_new = fine_tune(
        model_new, X_train_act, y_train_act, X_val_act, y_val_act,
        epochs_finetune, batch_size
    )

    # Tự động so sánh theo MSE trước
    if (metrics_new['mse']*1000) < (metrics_base['mse']*1000):
        model = model_new
        finetune_metrics = metrics_new
    elif (abs(metrics_new['mse'])*1000) == (abs(metrics_base['mse'])*1000): # MSE gần như bằng nhau thì chọn R2 cao hơn
        if metrics_new['r2'] > metrics_base['r2']:
            model = model_new
            finetune_metrics = metrics_new
        else:
            model = model_base
            finetune_metrics = metrics_base
    else:
        model = model_base
        finetune_metrics = metrics_base

    last_seq = scaled_actual[-lookback:].reshape(1, lookback, 1)
    future_scaled_preds = []

    for _ in range(predict_days):
        next_scaled = model.predict(last_seq, verbose=0)[0][0]
        future_scaled_preds.append(next_scaled)
        last_seq = np.append(last_seq[:, 1:, :], [[[next_scaled]]], axis=1)

    future_preds = scaler.inverse_transform(np.array(future_scaled_preds).reshape(-1, 1)).flatten()
    future_dates = pd.bdate_range(start=actual_df.index[-1] + pd.Timedelta(days=1), periods=predict_days)

    future_df = pd.DataFrame({
        'Date': future_dates,
        'Predicted Closing Price': future_preds
    })

    return model, future_df, finetune_metrics

"""Giá cổ phiếu CMG thực tế 3 ngày đó:
- `2025-02-26`: 44600 VNĐ
- `2025-02-27`: 44450 VNĐ
- `2025-02-28`: 44400 VNĐ
"""

"""Giá cổ phiếu FPT 3 ngày đó:
- `2025-03-13`: 136500 VNĐ
- `2025-03-14`: 131400 VNĐ
- `2025-03-17`: 130000 VNĐ
"""