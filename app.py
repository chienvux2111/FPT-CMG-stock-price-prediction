import streamlit as st
import numpy as np
import matplotlib.pyplot as plt 
import pandas as pd
import joblib
import json
import os
import time
import re
import requests
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# Import c√°c h√†m t·ª´ c√°c module
from meta_model import (
    lstm_train_finetune_predict,
    create_target,
    ultimate_clean,
    merging_df,
    predict_and_save, 
    run_all_models,  
    build_lstm_model,
    fine_tune_lstm_model,
    evaluate_model
)

from RAG import (
    load_raw_data as rag_load_raw_data, # ƒê·ªïi t√™n ƒë·ªÉ tr√°nh xung ƒë·ªôt n·∫øu c√≥
    clean_data as rag_clean_data,
    format_cleaned_data_to_text as rag_format_cleaned_data_to_text,
    create_embeddings as rag_create_embeddings,
    answer_query_with_rag,
    FILE_CONFIG as RAG_FILE_CONFIG # Import FILE_CONFIG t·ª´ RAG.py
)

# T·∫Øt c·∫£nh b√°o v√† t·∫£i bi·∫øn m√¥i tr∆∞·ªùng
import warnings
warnings.filterwarnings("ignore")
load_dotenv()
st.set_page_config(layout="wide")
st.title("·ª®ng d·ª•ng T√†i ch√≠nh: D·ª± b√°o Gi√° C·ªï phi·∫øu & H·ªèi ƒê√°p Th√¥ng Minh")
# ƒê·ªãnh nghƒ©a c√°c ƒë∆∞·ªùng d·∫´n
DATA_DIR_PREDICT = 'DATA EXPLORER CONTEST/Data/' # D·ªØ li·ªáu cho d·ª± ƒëo√°n
MODEL_DIR_PREDICT = 'meta model result'          # M√¥ h√¨nh cho d·ª± ƒëo√°n
NEWS_PATH_RAG = 'DATA EXPLORER CONTEST/News/'    # D·ªØ li·ªáu tin t·ª©c cho RAG

# C·∫•u h√¨nh Ollama v√† Model Embeddings cho RAG
OLLAMA_MODEL_RAG = os.getenv("OLLAMA_MODEL", "llama3.2:latest") # L·∫•y t·ª´ .env ho·∫∑c m·∫∑c ƒë·ªãnh
OLLAMA_BASE_URL_RAG = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434/v1")
EMBEDDING_MODEL_NAME_RAG = os.getenv("EMBEDDING_MODEL_NAME", 'paraphrase-multilingual-MiniLM-L12-v2')

# PH·∫¶N 1: KH·ªûI T·∫†O V√Ä CACHING CHO D·ª∞ B√ÅO GI√Å

@st.cache_data
def load_prediction_models_and_data():
    models = {}
    try:
        models['CMG'] = {
            'model': joblib.load(os.path.join(MODEL_DIR_PREDICT, "CMG/model/model.pkl")),
            'X_scaler': joblib.load(os.path.join(MODEL_DIR_PREDICT, "CMG/X_scaler/scaler.pkl")),
            'y_scaler': joblib.load(os.path.join(MODEL_DIR_PREDICT, "CMG/y_scaler/scaler.pkl")),
            'metrics': json.load(open(os.path.join(MODEL_DIR_PREDICT, "CMG/metrics/metrics.json"), 'r', encoding='utf-8')),
        }
        models['FPT'] = {
            'model': joblib.load(os.path.join(MODEL_DIR_PREDICT, "FPT/model/model.pkl")),
            'X_scaler': joblib.load(os.path.join(MODEL_DIR_PREDICT, "FPT/X_scaler/scaler.pkl")),
            'y_scaler': joblib.load(os.path.join(MODEL_DIR_PREDICT, "FPT/y_scaler/scaler.pkl")),
            'metrics': json.load(open(os.path.join(MODEL_DIR_PREDICT, "FPT/metrics/metrics.json"), 'r', encoding='utf-8')),
        }
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh d·ª± ƒëo√°n: {e}")
        return None, None, None, None

    # T·∫£i d·ªØ li·ªáu ƒë·∫ßu v√†o cho m√¥ h√¨nh d·ª± ƒëo√°n (v√≠ d·ª•: regressor_cmg, prediction_cmg)
    # Ph·∫ßn n√†y c·∫ßn ƒë·∫£m b·∫£o d·ªØ li·ªáu ƒë∆∞·ª£c chu·∫©n b·ªã ƒë√∫ng c√°ch.
    # D·ª±a tr√™n code g·ªëc, c√≥ v·∫ª nh∆∞ b·∫°n ƒë√£ c√≥ c√°c file CSV ch·ª©a prediction_cmg v√† prediction_fpt
    # v√† regressor_cmg/fpt ƒë∆∞·ª£c t·∫°o t·ª´ d·ªØ li·ªáu g·ªëc.
    try:
        data_hist = {
            "D·ªØ li·ªáu L·ªãch s·ª≠ CMG.csv": pd.read_csv(os.path.join(DATA_DIR_PREDICT, "D·ªØ li·ªáu L·ªãch s·ª≠ CMG.csv")),
            "D·ªØ li·ªáu L·ªãch s·ª≠ FPT.csv": pd.read_csv(os.path.join(DATA_DIR_PREDICT, "D·ªØ li·ªáu L·ªãch s·ª≠ FPT.csv")),
            "FPT_news_features.csv": pd.read_csv(os.path.join(DATA_DIR_PREDICT, "FPT_news_features.csv")),
            "CMG_news_features.csv": pd.read_csv(os.path.join(DATA_DIR_PREDICT, "CMG_news_features.csv")),
            "prediction_CMG_bctc.csv": pd.read_csv(os.path.join(DATA_DIR_PREDICT, "prediction_CMG_bctc.csv")),
            "prediction_CMG_market.csv": pd.read_csv(os.path.join(DATA_DIR_PREDICT, "prediction_CMG_market.csv")),
            "prediction_FPT_bctc.csv": pd.read_csv(os.path.join(DATA_DIR_PREDICT, "prediction_FPT_bctc.csv")),
            "prediction_FPT_market.csv": pd.read_csv(os.path.join(DATA_DIR_PREDICT, "prediction_FPT_market.csv"))
        }
        cleaned_hist_data = ultimate_clean(data_hist)
        merge_cmg = merging_df(cleaned_hist_data, 'CMG').dropna()
        merge_fpt = merging_df(cleaned_hist_data, 'FPT').dropna()

        regressor_cmg_df = create_target(merge_cmg, 'regression')
        regressor_fpt_df = create_target(merge_fpt, 'regression')

        # T·∫£i c√°c file prediction ƒë√£ ƒë∆∞·ª£c t·∫°o s·∫µn (quan tr·ªçng cho lstm_train_finetune_predict)
        prediction_cmg_df = pd.read_csv(os.path.join(MODEL_DIR_PREDICT, 'Total prediction value/prediction_CMG.csv'))
        prediction_fpt_df = pd.read_csv(os.path.join(MODEL_DIR_PREDICT, 'Total prediction value/prediction_FPT.csv'))

        return models, regressor_cmg_df, regressor_fpt_df, prediction_cmg_df, prediction_fpt_df
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i ho·∫∑c x·ª≠ l√Ω d·ªØ li·ªáu d·ª± ƒëo√°n: {e}")
        return models, None, None, None, None # Tr·∫£ v·ªÅ models ƒë·ªÉ √≠t nh·∫•t metrics c√≥ th·ªÉ hi·ªÉn th·ªã

prediction_models, regressor_cmg, regressor_fpt, prediction_cmg, prediction_fpt = load_prediction_models_and_data()

# PH·∫¶N 2: KH·ªûI T·∫†O V√Ä CACHING CHO H·ªéI & ƒê√ÅP RAG
@st.cache_resource
def load_embedding_model_rag():
    print(f"ST RAG: ƒêang t·∫£i embedding model: {EMBEDDING_MODEL_NAME_RAG}...")
    try:
        model = SentenceTransformer(EMBEDDING_MODEL_NAME_RAG)
        print("ST RAG: Embedding model ƒë√£ t·∫£i xong.")
        return model
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i embedding model cho RAG: {e}")
        return None

@st.cache_resource
def get_ollama_client_rag():
    print(f"ST RAG: ƒêang k·∫øt n·ªëi Ollama t·∫°i {OLLAMA_BASE_URL_RAG}...")
    try:
        client = OpenAI(base_url=OLLAMA_BASE_URL_RAG, api_key='ollama') # api_key th∆∞·ªùng l√† 'ollama' ho·∫∑c b·ªè tr·ªëng cho local
        print("ST RAG: ƒê√£ k·∫øt n·ªëi Ollama.")
        return client
    except Exception as e:
        st.error(f"L·ªói khi k·∫øt n·ªëi Ollama: {e}")
        return None

@st.cache_data
def prepare_rag_data(_file_config_rag, _embedding_model_rag):
    """ Chu·∫©n b·ªã d·ªØ li·ªáu cho RAG """
    if _embedding_model_rag is None:
        st.error("ST RAG: Embedding model ch∆∞a ƒë∆∞·ª£c t·∫£i, kh√¥ng th·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu RAG.")
        return None, None, False

    print("ST RAG: B·∫Øt ƒë·∫ßu chu·∫©n b·ªã d·ªØ li·ªáu RAG...")
    try:
        raw_data_rag = rag_load_raw_data(_file_config_rag) # S·ª≠ d·ª•ng h√†m ƒë√£ import t·ª´ RAG.py
        if not raw_data_rag:
            st.error("ST RAG L·ªói: Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu th√¥ cho RAG.")
            return None, None, False

        cleaned_data_rag = rag_clean_data(raw_data_rag) # S·ª≠ d·ª•ng h√†m ƒë√£ import
        if not cleaned_data_rag:
            st.error("ST RAG L·ªói: Kh√¥ng th·ªÉ l√†m s·∫°ch d·ªØ li·ªáu cho RAG.")
            return None, None, False

        all_texts_rag, _ = rag_format_cleaned_data_to_text(cleaned_data_rag, _file_config_rag) # S·ª≠ d·ª•ng h√†m ƒë√£ import
        if not all_texts_rag:
            st.error("ST RAG L·ªói: Kh√¥ng th·ªÉ ƒë·ªãnh d·∫°ng d·ªØ li·ªáu th√†nh vƒÉn b·∫£n cho RAG.")
            return None, None, False

        document_embeddings_rag = rag_create_embeddings(all_texts_rag, _embedding_model_rag) # S·ª≠ d·ª•ng h√†m ƒë√£ import
        if document_embeddings_rag is None:
            st.error("ST RAG L·ªói: T·∫°o Document Embeddings cho RAG th·∫•t b·∫°i.")
            return None, None, False

        print(f"ST RAG: Chu·∫©n b·ªã d·ªØ li·ªáu RAG ho√†n t·∫•t. {len(all_texts_rag)} vƒÉn b·∫£n.")
        return all_texts_rag, document_embeddings_rag, True
    except Exception as e:
        st.error(f"L·ªói trong qu√° tr√¨nh chu·∫©n b·ªã d·ªØ li·ªáu RAG: {e}")
        return None, None, False

# Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn RAG
embedding_model_rag_main = load_embedding_model_rag()
ollama_client_rag_main = get_ollama_client_rag()
all_texts_rag_main, document_embeddings_rag_main, rag_is_ready = prepare_rag_data(RAG_FILE_CONFIG, embedding_model_rag_main)

# PH·∫¶N 3: GIAO DI·ªÜN STREAMLIT
tab1, tab2 = st.tabs(["üí¨ H·ªèi & ƒê√°p RAG", "üìà D·ª± b√°o Gi√° C·ªï phi·∫øu"])

with tab1:
    st.header("H·ªèi & ƒê√°p Th√¥ng Minh (RAG)")
    if not rag_is_ready or ollama_client_rag_main is None:
        st.error("H·ªá th·ªëng H·ªèi & ƒê√°p RAG ch∆∞a s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra console ƒë·ªÉ bi·∫øt l·ªói chi ti·∫øt.")
    else:
        st.success(f"H·ªá th·ªëng RAG ƒë√£ s·∫µn s√†ng v·ªõi {len(all_texts_rag_main)} m·∫©u tin t·ª©c.")
        user_query_rag = st.text_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ tin t·ª©c FPT ho·∫∑c CMG:", key="rag_query_input", placeholder="V√≠ d·ª•: FPT c√≥ th√¥ng b√°o chia c·ªï t·ª©c n√†o g·∫ßn ƒë√¢y kh√¥ng?")

        if st.button("T√¨m c√¢u tr·∫£ l·ªùi", key="rag_button"):
            if not user_query_rag.strip():
                st.warning("Vui l√≤ng nh·∫≠p c√¢u h·ªèi.")
            else:
                with st.spinner("ƒêang t√¨m ki·∫øm v√† t·∫°o c√¢u tr·∫£ l·ªùi..."):
                    try:
                        start_time_rag = time.time()
                        answer_rag = answer_query_with_rag(
                            query=user_query_rag,
                            document_embeddings=document_embeddings_rag_main,
                            all_texts=all_texts_rag_main,
                            client=ollama_client_rag_main,
                            model_name=OLLAMA_MODEL_RAG,
                            embedding_model_obj=embedding_model_rag_main
                        )
                        end_time_rag = time.time()
                        processing_time_rag = end_time_rag - start_time_rag
                        st.subheader("C√¢u tr·∫£ l·ªùi t·ª´ H·ªá th·ªëng RAG:")
                        st.markdown(answer_rag if answer_rag else "Kh√¥ng t√¨m th·∫•y th√¥ng tin ho·∫∑c c√≥ l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω.")
                        st.caption(f"Th·ªùi gian x·ª≠ l√Ω RAG: {processing_time_rag:.2f} gi√¢y")
                    except Exception as e:
                        st.error(f"L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi RAG: {e}")
        st.subheader('H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng (H·ªèi & ƒê√°p RAG)')
        st.markdown(
        """
        - Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n li√™n quan ƒë·∫øn tin t·ª©c c·ªßa FPT ho·∫∑c CMG v√†o √¥ vƒÉn b·∫£n.
        - Nh·∫•n "T√¨m c√¢u tr·∫£ l·ªùi".
        - H·ªá th·ªëng s·∫Ω s·ª≠ d·ª•ng ki·∫øn th·ª©c t·ª´ csdl b·∫£n tin ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n.
        """
        )

with tab2:
    st.header("D·ª± b√°o Gi√° C·ªï phi·∫øu")
    if prediction_models and regressor_cmg is not None and prediction_cmg is not None: # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ t·∫£i th√†nh c√¥ng
        ticker = st.selectbox('Ch·ªçn m√£ c·ªï phi·∫øu', ['CMG', 'FPT'], key='ticker_predict')
        setting = prediction_models[ticker]

        st.subheader(f'Hi·ªáu su·∫•t m√¥ h√¨nh Meta cho {ticker}')
        # Hi·ªÉn th·ªã c√°c metrics b·∫°n mu·ªën t·ª´ setting['metrics']
        # V√≠ d·ª•:
        metrics_display = {k: f"{round(v,4)}%" for k, v in setting['metrics'].items() if k in ['mse', 'mae', 'rmse']}
        st.json(metrics_display)


        days_to_predict = st.slider('S·ªë ng√†y d·ª± b√°o', min_value=1, max_value=7, value=3, key='days_slider')
        st.subheader(f'D·ª± b√°o gi√° {ticker} cho {days_to_predict} ng√†y t·ªõi')

        if st.button('B·∫Øt ƒë·∫ßu d·ª± b√°o', key='predict_button'):
            current_regressor = regressor_cmg if ticker == 'CMG' else regressor_fpt
            current_prediction_df = prediction_cmg if ticker == 'CMG' else prediction_fpt

            if current_regressor.empty or current_prediction_df.empty:
                st.error(f"D·ªØ li·ªáu c·∫ßn thi·∫øt cho d·ª± b√°o {ticker} ch∆∞a s·∫µn s√†ng.")
            else:
                with st.spinner(f"ƒêang d·ª± b√°o cho {ticker}..."):
                    try:
                        start_time_predict = time.time()
                        _, future_df, fut_metrics = lstm_train_finetune_predict(
                            pred_df=current_prediction_df, # ƒê√¢y l√† DataFrame d·ª± ƒëo√°n t·ª´ meta-model
                            actual_df=current_regressor[['Target']], # ƒê√¢y l√† DataFrame gi√° th·ª±c t·∫ø
                            scaler=setting['X_scaler'], # Scaler c·ªßa meta-model
                            predict_days=days_to_predict
                        )
                        end_time_predict = time.time()
                        processing_time_predict = end_time_predict - start_time_predict
                        st.markdown(f'**K·∫øt qu·∫£ d·ª± b√°o {days_to_predict} ng√†y ti·∫øp theo cho {ticker}**')
                        st.dataframe(future_df.set_index('Date')) # D√πng dataframe ƒë·ªÉ hi·ªÉn th·ªã t·ªët h∆°n
                        st.markdown(f"**Ch·ªâ s·ªë ƒë√°nh gi√° c·ªßa m√¥ h√¨nh LSTM tinh ch·ªânh:**")
                        st.json({
                            'mse': f"{round(fut_metrics['mse'],4)}%",
                            'mae': f"{round(fut_metrics['mae'],4)}%",
                            'rmse': f"{round(fut_metrics['rmse'],4)}%"
                        }) # Hi·ªÉn th·ªã c√°c metrics c·ªßa LSTM
                        st.caption(f"Th·ªùi gian x·ª≠ l√Ω d·ª± b√°o: {processing_time_predict:.2f} gi√¢y")
                        # Bi·ªÉu ƒë·ªì
                        chart_data = future_df.set_index('Date')[['Predicted Closing Price']]
                        st.line_chart(chart_data)
                    except Exception as e:
                        st.error(f"L·ªói trong qu√° tr√¨nh d·ª± b√°o LSTM: {e}")
        else:
            st.info("Nh·∫•n n√∫t 'B·∫Øt ƒë·∫ßu d·ª± b√°o' ƒë·ªÉ xem k·∫øt qu·∫£.")

        st.subheader('H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng (D·ª± b√°o)')
        st.markdown(
        """
        - Ch·ªçn m√£ CMG ho·∫∑c FPT t·ª´ menu th·∫£ xu·ªëng.
        - Ch·ªçn s·ªë ng√†y b·∫°n mu·ªën d·ª± b√°o b·∫±ng thanh tr∆∞·ª£t.
        - Nh·∫•n "B·∫Øt ƒë·∫ßu d·ª± b√°o" ƒë·ªÉ xem gi√° d·ª± ƒëo√°n, c√°c ch·ªâ s·ªë ƒë√°nh gi√° v√† bi·ªÉu ƒë·ªì xu h∆∞·ªõng.
        - C√°c ch·ªâ s·ªë hi·ªáu su·∫•t hi·ªÉn th·ªã ban ƒë·∫ßu l√† c·ªßa m√¥ h√¨nh Meta ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc.
        - C√°c ch·ªâ s·ªë sau khi d·ª± b√°o l√† c·ªßa m√¥ h√¨nh LSTM ƒë∆∞·ª£c tinh ch·ªânh nhanh cho vi·ªác d·ª± b√°o ng·∫Øn h·∫°n.
        """
        )
    else:
        st.error("Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu ho·∫∑c m√¥ h√¨nh c·∫ßn thi·∫øt cho ch·ª©c nƒÉng d·ª± b√°o. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh v√† ƒë∆∞·ªùng d·∫´n file.")


